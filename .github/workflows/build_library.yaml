name: Build library

on:
  push:
    paths:
      - .github/workflows/build_library.yaml
      - CMakeLists.txt
      - undreamai.h
      - undreamai.cpp
    tags:
      - 'v*'

env:
  LLAMACPP_VERSION: b3184
  LLAMAFILE_VERSION: 0.8.6
  CMAKE_COMMON_JOBS: '-DLLAMA_STATIC=ON -DLLAMA_BUILD_TESTS=OFF -DLLAMA_BUILD_EXAMPLES=OFF -DCMAKE_RUNTIME_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DBUILD_UNDREAMAI_SERVER=ON'

jobs:
  ################################ ArchChecker ################################

  archchecker_linux_build:
    name: Build ArchChecker Linux
    runs-on: ubuntu-latest

    steps:
      - name: Clone
        id: checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Build
        id: build
        run: |
          mkdir archchecker/build
          cd archchecker/build
          cmake ..
          cmake --build . --config Release -j ${env:NUMBER_OF_PROCESSORS}

      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: linux-archchecker
          path: archchecker/build/libarchchecker.so


  archchecker_windows_build:
    name: Build ArchChecker Windows
    runs-on: windows-latest

    steps:
      - name: Clone
        id: checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Build
        id: build
        run: |
          mkdir archchecker/build
          cd archchecker/build
          cmake ..
          cmake --build . --config Release -j ${env:NUMBER_OF_PROCESSORS}

      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: windows-archchecker
          path: archchecker/build/Release/archchecker.dll

  ################################ Linux ################################

  linux_build:
    name: Build Artifacts
    runs-on: ubuntu-latest

    env:
      CMAKE_COMMON: '-DLLAMA_NATIVE=OFF -DCMAKE_BUILD_RPATH_USE_ORIGIN=ON'

    strategy:
      matrix:
        include:
          - build: 'noavx'
            defines: '-DLLAMA_AVX=OFF -DLLAMA_AVX2=OFF -DLLAMA_FMA=OFF'
          - build: 'avx2'
            defines: ''
          - build: 'avx'
            defines: '-DLLAMA_AVX2=OFF'
          - build: 'avx512'
            defines: '-DLLAMA_AVX512=ON'
          - build: 'vulkan'
            defines: '-DLLAMA_VULKAN=ON'
          - build: 'cuda-cu11.7.1'
            defines: '-DLLAMA_CUDA=ON -DCUDAToolkit_ROOT="$GITHUB_WORKSPACE/build/cuda"'
          - build: 'cuda-cu12.2.0'
            defines: '-DLLAMA_CUDA=ON -DCUDAToolkit_ROOT="$GITHUB_WORKSPACE/build/cuda"'
            
    steps:
      - name: Clone
        id: checkout
        uses: actions/checkout@v4

      - name: Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install build-essential cmake

      - name: Get Variables
        run: |
          echo "CUDA=$(echo "${{ matrix.build }}" | cut -d '-' -f2 | cut -c 3- )" >> $GITHUB_ENV

      - name: Clone llama.cpp
        run: |
          git clone https://github.com/ggerganov/llama.cpp llama.cpp
          cd llama.cpp
          git checkout ${{ env.LLAMACPP_VERSION }}
          sed -i 's:utils.hpp:utils_callback.hpp:g' examples/server/server.cpp
          sed -i 's:main(int argc:main_server(int argc:g' examples/server/server.cpp
          cd ..
          mkdir -p build/licenses build/libs
          cp llama.cpp/LICENSE build/licenses/llama.cpp.LICENSE.txt

      - name: Create missing files
        run: |
          cd llama.cpp
          for f in examples/server/public/*;do
            cmake -DINPUT=$f -DOUTPUT=`echo $f|sed -e 's:public/::g'`.hpp -P scripts/xxd.cmake
          done

      - name: Dependencies Vulcan
        if: matrix.build == 'vulkan'
        run: |
          sudo apt-get install libvulkan-dev
          cp /lib/x86_64-linux-gnu/libvulkan.so.1 build/libs/

      - name: Prepare CUDA
        if: startsWith(matrix.build, 'cuda')
        run: |
          cp tinyBLAS/${{ env.LLAMACPP_VERSION }}/* llama.cpp/
          rm -r llama.cpp/ggml-cuda
          sed -i 's:GGML_USE_CUDA:GGML_USE_CUDA GGML_USE_TINYBLAS NDEBUG:g' llama.cpp/CMakeLists.txt

      - uses: Jimver/cuda-toolkit@v0.2.11
        id: cuda-toolkit
        if: startsWith(matrix.build, 'cuda')
        with:
          cuda: ${{ env.CUDA }}
          method: 'network'
          linux-local-args: '["--toolkit"]'

      - name: Link Cuda
        if: startsWith(matrix.build, 'cuda')
        run: |
          ln -s ${{ env.CUDA_PATH }} ${{ github.workspace }}/build/cuda

      - name: Build
        id: cmake_build
        run: |
          sed -i "s:LIBRARY undreamai:LIBRARY undreamai_linux-${{ matrix.build }}:g" CMakeLists.txt
          export LD_LIBRARY_PATH=""
          cd build
          cmake .. ${{ matrix.defines }} ${{ env.CMAKE_COMMON }} ${{ env.CMAKE_COMMON_JOBS }}
          cmake --build . --config Release -j ${env:NUMBER_OF_PROCESSORS}

      - name: Test
        id: test
        if: matrix.build == 'avx'
        run: |
          cd build/libs
          curl -L -o model.gguf https://huggingface.co/afrideva/smol_llama-220M-openhermes-GGUF/resolve/main/smol_llama-220m-openhermes.q4_k_m.gguf?download=true
          ./undreamai_test -m model.gguf -np 1 --log-disable
          rm model.gguf

      - name: Pack artifacts
        id: pack_artifacts
        run: |
          rm build/libs/undreamai_test
          zip -j undreamai-${{ github.ref_name }}-llamacpp-linux-${{ matrix.build }}.zip build/licenses/* build/libs/*

      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: undreamai-${{ github.ref_name }}-llamacpp-linux-${{ matrix.build }}.zip
          path: undreamai-${{ github.ref_name }}-llamacpp-linux-${{ matrix.build }}.zip

################################ macOS ################################

  macOS-arm64-build:
    runs-on: macos-14

    strategy:
      matrix:
        include:
          - build: 'no_acc'
            defines: '-DLLAMA_ACCELERATE=OFF'
          - build: 'acc'
            defines: ''

    steps:
      - name: Clone
        id: checkout
        uses: actions/checkout@v4

      - name: Clone llama.cpp
        run: |
          git clone https://github.com/ggerganov/llama.cpp llama.cpp
          cd llama.cpp
          git checkout ${{ env.LLAMACPP_VERSION }}
          sed -i.bak 's:utils.hpp:utils_callback.hpp:g' examples/server/server.cpp
          sed -i.bak 's:main(int argc:main_server(int argc:g' examples/server/server.cpp
          cd ..
          mkdir -p build/licenses build/libs
          cp llama.cpp/LICENSE build/licenses/llama.cpp.LICENSE.txt

      - name: Create missing files
        run: |
          cd llama.cpp
          for f in examples/server/public/*;do
            cmake -DINPUT=$f -DOUTPUT=`echo $f|sed -e 's:public/::g'`.hpp -P scripts/xxd.cmake
          done
  
      - name: Dependencies
        id: depends
        continue-on-error: true
        run: |
          brew update

      - name: Build
        id: cmake_build
        run: |
          sed -i.bak "s:LIBRARY undreamai:LIBRARY undreamai_macos-arm64-${{ matrix.build }}:g" CMakeLists.txt
          cd build
          cmake -DLLAMA_FATAL_WARNINGS=ON -DLLAMA_METAL_EMBED_LIBRARY=ON -DLLAMA_CURL=ON ${{ matrix.defines }} ${{ env.CMAKE_COMMON_JOBS }} ..
          cmake --build . --config Release -j $(sysctl -n hw.logicalcpu)

      - name: Pack artifacts
        id: pack_artifacts
        run: |
          rm build/libs/undreamai_test
          ls -R build
          zip -j undreamai-${{ github.ref_name }}-llamacpp-macos-arm64-${{ matrix.build }}.zip build/licenses/* build/libs/*

      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: undreamai-${{ github.ref_name }}-llamacpp-macos-arm64-${{ matrix.build }}.zip
          path: undreamai-${{ github.ref_name }}-llamacpp-macos-arm64-${{ matrix.build }}.zip

  macOS-x64-build:
    runs-on: macos-12

    strategy:
      matrix:
        include:
          - build: 'no_acc'
            defines: '-DLLAMA_ACCELERATE=OFF'
          - build: 'acc'
            defines: ''

    steps:
      - name: Clone
        id: checkout
        uses: actions/checkout@v4

      - name: Clone llama.cpp
        run: |
          git clone https://github.com/ggerganov/llama.cpp llama.cpp
          cd llama.cpp
          git checkout ${{ env.LLAMACPP_VERSION }}
          sed -i.bak 's:utils.hpp:utils_callback.hpp:g' examples/server/server.cpp
          sed -i.bak 's:main(int argc:main_server(int argc:g' examples/server/server.cpp
          cd ..
          mkdir -p build/licenses build/libs
          cp llama.cpp/LICENSE build/licenses/llama.cpp.LICENSE.txt

      - name: Create missing files
        run: |
          cd llama.cpp
          for f in examples/server/public/*;do
            cmake -DINPUT=$f -DOUTPUT=`echo $f|sed -e 's:public/::g'`.hpp -P scripts/xxd.cmake
          done
  
      - name: Dependencies
        id: depends
        continue-on-error: true
        run: |
          brew update

      - name: Build
        id: cmake_build
        run: |
          sed -i.bak "s:LIBRARY undreamai:LIBRARY undreamai_macos-x64-${{ matrix.build }}:g" CMakeLists.txt
          cd build
          cmake -DLLAMA_FATAL_WARNINGS=ON -DLLAMA_METAL=OFF -DLLAMA_CURL=ON ${{ matrix.defines }} ${{ env.CMAKE_COMMON_JOBS }} ..
          cmake --build . --config Release -j $(sysctl -n hw.logicalcpu)

      - name: Test
        id: test
        run: |
          cd build/libs
          curl -L -o model.gguf https://huggingface.co/afrideva/smol_llama-220M-openhermes-GGUF/resolve/main/smol_llama-220m-openhermes.q4_k_m.gguf?download=true
          ./undreamai_test -m model.gguf -np 1 --log-disable
          rm model.gguf

      - name: Pack artifacts
        id: pack_artifacts
        run: |
          rm build/libs/undreamai_test
          ls -R build
          zip -j undreamai-${{ github.ref_name }}-llamacpp-macos-x64-${{ matrix.build }}.zip build/licenses/* build/libs/*

      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: undreamai-${{ github.ref_name }}-llamacpp-macos-x64-${{ matrix.build }}.zip
          path: undreamai-${{ github.ref_name }}-llamacpp-macos-x64-${{ matrix.build }}.zip

################################ Windows ################################

  windows-build:
    runs-on: windows-latest

    env:
      CMAKE_COMMON: '-DLLAMA_NATIVE=OFF'
      VULKAN_VERSION: 1.3.261.1
    
    strategy:
      matrix:
        include:
          - build: 'noavx'
            defines: '-DLLAMA_AVX=OFF -DLLAMA_AVX2=OFF -DLLAMA_FMA=OFF'
          - build: 'avx2'
            defines: ''
          - build: 'avx'
            defines: '-DLLAMA_AVX2=OFF'
          - build: 'avx512'
            defines: '-DLLAMA_AVX512=ON'
          - build: 'vulkan'
            defines: '-DLLAMA_VULKAN=ON'
          - build: 'arm64'
            defines: '-A ARM64'

    steps:
      - name: Clone
        id: checkout
        uses: actions/checkout@v4

      - name: Get Variables
        run: |
          $pattern = "\d+\.\d+\.\d+"
          $CUDA = [regex]::Match("${{ matrix.build }}", $pattern).Value
          Add-Content $env:GITHUB_ENV "CUDA=$CUDA"

      - name: Clone llama.cpp
        run: |
          git clone https://github.com/ggerganov/llama.cpp llama.cpp
          cd llama.cpp
          git checkout ${{ env.LLAMACPP_VERSION }}
          (Get-Content examples/server/server.cpp ) -replace 'utils.hpp', 'utils_callback.hpp' | Set-Content examples/server/server.cpp
          (Get-Content examples/server/server.cpp ) -replace 'main\(int argc', 'main_server(int argc' | Set-Content examples/server/server.cpp
          cd ..
          mkdir build

      - name: Create missing files
        shell: bash
        run: |
          cd llama.cpp
          for f in examples/server/public/*; do
            cmake -DINPUT=$f -DOUTPUT=$(echo $f | sed -e 's:public/::g').hpp -P scripts/xxd.cmake
          done

      - name: Install Vulkan SDK
        id: get_vulkan
        if: matrix.build == 'vulkan'
        run: |
          curl.exe -o $env:RUNNER_TEMP/VulkanSDK-Installer.exe -L "https://sdk.lunarg.com/sdk/download/${env:VULKAN_VERSION}/windows/VulkanSDK-${env:VULKAN_VERSION}-Installer.exe"
          & "$env:RUNNER_TEMP\VulkanSDK-Installer.exe" --accept-licenses --default-answer --confirm-command install
          Add-Content $env:GITHUB_ENV "VULKAN_SDK=C:\VulkanSDK\${env:VULKAN_VERSION}"
          Add-Content $env:GITHUB_PATH "C:\VulkanSDK\${env:VULKAN_VERSION}\bin"
          curl.exe -o $env:RUNNER_TEMP/VulkanRT-Components.zip -L "https://sdk.lunarg.com/sdk/download/1.3.283.0/windows/VulkanRT-1.3.283.0-Components.zip"
          7z x "-o${env:RUNNER_TEMP}" $env:RUNNER_TEMP/VulkanRT-Components.zip
          mkdir .\build\libs\Release
          cp ${env:RUNNER_TEMP}/VulkanRT*\x64\vulkan-1.dll .\build\libs\Release

      - name: Build
        id: cmake_build
        run: |
          (Get-Content CMakeLists.txt ) -replace 'LIBRARY undreamai', 'LIBRARY undreamai_windows-${{ matrix.build }}' | Set-Content CMakeLists.txt
          cd build
          cmake .. ${{ matrix.defines }} ${{ env.CMAKE_COMMON }} ${{ env.CMAKE_COMMON_JOBS }} 
          cmake --build . --config Release -j ${env:NUMBER_OF_PROCESSORS}

      - name: Pack artifacts
        id: pack_artifacts
        run: |
          del build/libs/Release/undreamai_test.exe
          mkdir artifacts
          ls -R build
          Copy-Item .\llama.cpp\LICENSE .\artifacts\llama.cpp.LICENSE.txt
          Copy-Item .\build\Release\* .\artifacts\
          Copy-Item .\build\libs\Release\*dll .\artifacts\
          $serverPath = ".\build\libs\Release\undreamai_server.exe"
          if (Test-Path $serverPath) {
              Copy-Item $serverPath -Destination ".\artifacts\"
          }
          cd artifacts
          7z a ../undreamai-${{ github.ref_name }}-llamacpp-windows-${{ matrix.build }}.zip *

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          path: undreamai-${{ github.ref_name }}-llamacpp-windows-${{ matrix.build }}.zip
          name: undreamai-${{ github.ref_name }}-llamacpp-windows-${{ matrix.build }}.zip


  windows-cuda-build:
    runs-on: windows-2019

    env:
      CMAKE_COMMON: '-DLLAMA_NATIVE=OFF'
    
    strategy:
      matrix:
        include:
          - build: 'cuda-cu11.7.1'
            defines: '-DLLAMA_CUDA=ON'
          - build: 'cuda-cu12.2.0'
            defines: '-DLLAMA_CUDA=ON'

    steps:
      - name: Clone
        id: checkout
        uses: actions/checkout@v4

      - name: Get Variables
        run: |
          $pattern = "\d+\.\d+\.\d+"
          $CUDA = [regex]::Match("${{ matrix.build }}", $pattern).Value
          Add-Content $env:GITHUB_ENV "CUDA=$CUDA"

      - name: Clone llama.cpp
        run: |
          git clone https://github.com/ggerganov/llama.cpp llama.cpp
          cd llama.cpp
          git checkout ${{ env.LLAMACPP_VERSION }}
          (Get-Content examples/server/server.cpp ) -replace 'utils.hpp', 'utils_callback.hpp' | Set-Content examples/server/server.cpp
          (Get-Content examples/server/server.cpp ) -replace 'main\(int argc', 'main_server(int argc' | Set-Content examples/server/server.cpp

      - name: Create missing files
        run: |
          cd llama.cpp
          Get-ChildItem examples/server/public/* | ForEach-Object {
            $f = $_.FullName
            $output = $f -replace "public\\", ""
            echo "cmake -DINPUT=$f -DOUTPUT=$output.hpp -P scripts/xxd.cmake"
            cmake -DINPUT="$f" -DOUTPUT="$output.hpp" -P "scripts/xxd.cmake"
          }
          
      - name: Prepare CUDA
        run: |
          cp tinyBLAS/${env:LLAMACPP_VERSION}/* llama.cpp\
          rm -r llama.cpp/ggml-cuda
          sed -i "s/GGML_USE_CUDA/GGML_USE_CUDA GGML_USE_TINYBLAS NDEBUG/g" llama.cpp\CMakeLists.txt

      - uses: Jimver/cuda-toolkit@v0.2.11
        id: cuda-toolkit
        with:
          cuda: ${{ env.CUDA }}
          method: 'network'
          sub-packages: '["nvcc", "cudart", "cublas", "cublas_dev", "thrust", "visual_studio_integration"]'

      - name: Build
        id: cmake_build
        run: |
          (Get-Content CMakeLists.txt ) -replace 'LIBRARY undreamai', 'LIBRARY undreamai_windows-${{ matrix.build }}' | Set-Content CMakeLists.txt
          mkdir build
          cd build
          cmake .. ${{ matrix.defines }} ${{ env.CMAKE_COMMON }} ${{ env.CMAKE_COMMON_JOBS }} 
          cmake --build . --config Release -j ${env:NUMBER_OF_PROCESSORS}

      - name: Pack artifacts
        id: pack_artifacts
        run: |
          del build/libs/Release/undreamai_test.*
          mkdir artifacts
          ls -R build
          Copy-Item .\llama.cpp\LICENSE .\artifacts\llama.cpp.LICENSE.txt
          Copy-Item .\build\Release\* .\artifacts\
          Copy-Item .\build\libs\Release\*dll .\artifacts\
          $serverPath = ".\build\libs\Release\undreamai_server.exe"
          if (Test-Path $serverPath) {
              Copy-Item $serverPath -Destination ".\artifacts\"
          }
          cd artifacts
          7z a ../undreamai-${{ github.ref_name }}-llamacpp-windows-${{ matrix.build }}.zip *

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          path: undreamai-${{ github.ref_name }}-llamacpp-windows-${{ matrix.build }}.zip
          name: undreamai-${{ github.ref_name }}-llamacpp-windows-${{ matrix.build }}.zip

################################ Android ################################

  # android-build:
  #   runs-on: ubuntu-latest
  #   steps:
  #       - name: Clone
  #         id: checkout
  #         uses: actions/checkout@v4

  #       - name: Dependencies
  #         run: |
  #           sudo apt-get update
  #           sudo apt-get install build-essential cmake

  #       - name: Get Variables
  #         run: |
  #           echo "NDK=$ANDROID_NDK" >> $GITHUB_ENV

  #       - name: Clone llama.cpp
  #         run: |
  #           git clone https://github.com/ggerganov/llama.cpp llama.cpp
  #           cd llama.cpp
  #           git checkout ${{ env.LLAMACPP_VERSION }}
  #           sed -i 's:utils.hpp:utils_callback.hpp:g' examples/server/server.cpp
  #           sed -i 's:main(int argc:main_server(int argc:g' examples/server/server.cpp
  #           cd ..
  #           mkdir -p build/licenses build/libs
  #           cp llama.cpp/LICENSE build/licenses/llama.cpp.LICENSE.txt

  #       - name: Create missing files
  #         run: |
  #           cd llama.cpp
  #           for f in examples/server/public/*;do
  #             cmake -DINPUT=$f -DOUTPUT=`echo $f|sed -e 's:public/::g'`.hpp -P scripts/xxd.cmake
  #           done

  #       - name: Build
  #         id: cmake_build
  #         run: |
  #           sed -i "s:LIBRARY undreamai:LIBRARY undreamai_android:g" CMakeLists.txt
  #           export LD_LIBRARY_PATH=""
  #           cd build
  #           cmake .. -DCMAKE_TOOLCHAIN_FILE=$NDK/build/cmake/android.toolchain.cmake -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-23 -DCMAKE_C_FLAGS=-march=armv8.4a+dotprod ${{ env.CMAKE_COMMON_JOBS }}
  #           cmake --build . --config Release -j ${env:NUMBER_OF_PROCESSORS}

  #       - name: Pack artifacts
  #         id: pack_artifacts
  #         run: |
  #           rm build/libs/undreamai_test build/libs/undreamai_server
  #           zip -j undreamai-${{ github.ref_name }}-llamacpp-android.zip build/licenses/* build/libs/*

  #       - name: Upload Artifacts
  #         uses: actions/upload-artifact@v4
  #         with:
  #           name: undreamai-${{ github.ref_name }}-llamacpp-android.zip
  #           path: undreamai-${{ github.ref_name }}-llamacpp-android.zip

################################ Release ################################

  create_release:
    name: Create Release
    runs-on: ubuntu-latest
    needs:
      - archchecker_linux_build
      - archchecker_windows_build
      - linux_build
      - macOS-arm64-build
      - macOS-x64-build
      - windows-build
      - windows-cuda-build
      # - android-build
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download Artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Merge artifacts
        run: |
          cd artifacts
          ls -R
          PREFIX=undreamai-${{ github.ref_name }}-llamacpp

          for d in `ls | grep $PREFIX`;do
            cd $d; unzip $d; rm $d; cd ..;
            new_name=`echo $d | sed -e "s:$PREFIX-::g" | sed -e 's:.zip::g'`
            mv $d $new_name;
            echo $new_name >> bundle
          done

          servers=`find . -name undreamai_server*`
          if [ "$servers" != "" ];then
            zip -r undreamai-${{ github.ref_name }}-server.zip $servers
            rm $servers
          fi
          zip -r $PREFIX.zip `cat bundle` linux-archchecker windows-archchecker

      - name: Release
        uses: softprops/action-gh-release@v2
        with:
          name: "Release ${{ github.ref_name }}"
          files: "artifacts/*.zip"
