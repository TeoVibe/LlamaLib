name: Build library

on:
  push:
    paths:
      - .github/workflows/build_library_test.yaml
    # paths:
    #   - .github/workflows/build_library.yaml
    #   - CMakeLists.txt
    #   - undreamai.h
    #   - undreamai.cpp
    # tags:
    #   - 'v*'

env:
  LLAMACPP_VERSION: b3580
  CMAKE_COMMON_JOBS: '-DGGML_STATIC=ON -DLLAMA_BUILD_TESTS=OFF -DLLAMA_BUILD_EXAMPLES=OFF -DBUILD_UNDREAMAI_SERVER=ON -DBUILD_SHARED_LIBS=OFF'
  CMAKE_COMMON_DIR: -DCMAKE_RUNTIME_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=${{ github.workspace }}/build/libs

jobs:
  ################################ ArchChecker ################################

  archchecker_linux_build:
    name: Build ArchChecker Linux
    runs-on: ubuntu-latest

    env:
        UPLOAD_NAME: linux-archchecker
        UPLOAD_PATH: archchecker/build/libarchchecker.so

    steps:
        - id: checkout_recursive
          name: Clone
          uses: actions/checkout@v4
          with:
            submodules: recursive

        - id: build_archchecker
          name: Build
          run: |
            mkdir archchecker/build
            cd archchecker/build
            cmake ..
            cmake --build . --config Release -j $(nproc)

        - id: upload
          name: Upload Artifacts
          uses: actions/upload-artifact@v4
          with:
            name: ${{ env.UPLOAD_NAME }}
            path: ${{ env.UPLOAD_PATH }}


  archchecker_windows_build:
    name: Build ArchChecker Windows
    runs-on: windows-2019

    env:
        UPLOAD_NAME: windows-archchecker
        UPLOAD_PATH: archchecker/build/Release/archchecker.dll

    steps:
        - id: checkout_recursive
          name: Clone
          uses: actions/checkout@v4
          with:
            submodules: recursive

        - id: build_archchecker
          name: Build
          run: |
            mkdir archchecker/build
            cd archchecker/build
            cmake ..
            cmake --build . --config Release -j $(nproc)

        - id: upload
          name: Upload Artifacts
          uses: actions/upload-artifact@v4
          with:
            name: ${{ env.UPLOAD_NAME }}
            path: ${{ env.UPLOAD_PATH }}



  ################################ Linux ################################

  linux-build:
    runs-on: ubuntu-22.04

    env:
      CMAKE_COMMON: '-DGGML_NATIVE=OFF -DCMAKE_BUILD_RPATH_USE_ORIGIN=ON'

    strategy:
      matrix:
        include:
          - build: 'noavx'
            defines: '-DGGML_AVX=OFF -DGGML_AVX2=OFF -DGGML_FMA=OFF'
          - build: 'avx2'
            defines: ''
          - build: 'avx'
            defines: '-DGGML_AVX2=OFF'
          - build: 'avx512'
            defines: '-DGGML_AVX512=ON'
          - build: 'vulkan'
            defines: '-DGGML_VULKAN=ON'
          - build: 'cuda-cu11.7.1'
            defines: '-DGGML_CUDA=ON -DCUDAToolkit_ROOT="$GITHUB_WORKSPACE/build/cuda"'
          - build: 'cuda-cu12.2.0'
            defines: '-DGGML_CUDA=ON -DCUDAToolkit_ROOT="$GITHUB_WORKSPACE/build/cuda"'
            
    steps:
        - id: checkout
          name: Clone
          uses: actions/checkout@v4

        - id: setup_libs_linux
          name: Dependencies
          run: |
            sudo apt-get update
            sudo apt-get install build-essential cmake zip

        - id: setup_llama_cpp_linux
          name: Clone llama.cpp
          run: |
            git clone https://github.com/ggerganov/llama.cpp llama.cpp
            cd llama.cpp
            git checkout ${{ env.LLAMACPP_VERSION }}
        
            sed -i 's:utils.hpp:utils_callback.hpp:g' examples/server/server.cpp
            sed -i 's:main(int argc:main_server(int argc:g' examples/server/server.cpp
            sed -i 's:exit(1):std\:\:terminate():g' ggml/src/ggml-vulkan.cpp
        
            for f in examples/server/public/*;do
              cmake -DINPUT=$f -DOUTPUT=`echo $f|sed -e 's:public/::g'`.hpp -P scripts/xxd.cmake
            done
        
            cd ..
            mkdir -p build/licenses build/libs
            cp llama.cpp/LICENSE build/licenses/llama.cpp.LICENSE.txt

        - id: setup_vulcan_linux
          if: matrix.build == 'vulkan'
          name: Dependencies Vulcan
          run: |
            wget -qO - https://packages.lunarg.com/lunarg-signing-key-pub.asc | sudo apt-key add -
            sudo wget -qO /etc/apt/sources.list.d/lunarg-vulkan-jammy.list https://packages.lunarg.com/vulkan/lunarg-vulkan-jammy.list
            sudo apt-get update -y
            sudo apt-get install -y build-essential vulkan-sdk
            cp /lib/x86_64-linux-gnu/libvulkan.so.1 build/libs/

        - id: prepare_cuda_linux
          if: startsWith(matrix.build, 'cuda')
          name: Prepare CUDA
          run: |
            echo "CUDA=$(echo "${{ matrix.build }}" | cut -d '-' -f2 | cut -c 3- )" >> $GITHUB_ENV
            cp tinyBLAS/${{ env.LLAMACPP_VERSION }}/* llama.cpp/ggml/src/
            rm -r llama.cpp/ggml/src/ggml-cuda
            sed -i 's:GGML_USE_CUDA:GGML_USE_CUDA GGML_USE_TINYBLAS NDEBUG GGML_MINIMIZE_CODE_SIZE:g' llama.cpp/ggml/src/CMakeLists.txt
            curl -o build/licenses/llamafile.LICENSE.txt -L https://raw.githubusercontent.com/Mozilla-Ocho/llamafile/main/LICENSE

        - id: setup_cuda_linux
          if: startsWith(matrix.build, 'cuda')
          uses: Jimver/cuda-toolkit@v0.2.15
          with:
            cuda: ${{ env.CUDA }}
            linux-local-args: '["--toolkit"]'
            method: network

        - id: link_cuda_linux
          if: startsWith(matrix.build, 'cuda')
          name: Link Cuda
          run: |
            ln -s ${{ env.CUDA_PATH }} ${{ github.workspace }}/build/cuda

        - id: set_build_params_linux
          name: Set build parameters
          run: |
            echo "BUILD_PARAMS=${{ matrix.defines }} ${{ env.CMAKE_COMMON }} ${{ env.CMAKE_COMMON_JOBS }} ${{ env.CMAKE_COMMON_DIR }}" >> $GITHUB_ENV

        - id: cmake_build_linux
          name: Build
          run: |
            sed -i "s:LIBRARY undreamai:LIBRARY undreamai_linux-${{ matrix.build }}:g" CMakeLists.txt
            export LD_LIBRARY_PATH=""
            cd build
            cmake .. ${{ env.BUILD_PARAMS }}
            cmake --build . --config Release -j $(nproc)

        - id: test_build_linux
          if: matrix.build == 'avx'
          name: Test
          run: |
            cd build/libs
            curl -L -o model.gguf https://huggingface.co/afrideva/smol_llama-220M-openhermes-GGUF/resolve/main/smol_llama-220m-openhermes.q4_k_m.gguf?download=true
            ./undreamai_test -m model.gguf -np 1 --log-disable
            rm model.gguf

        - id: set_upload_name_linux
          name: Set upload name
          run: |
            echo "UPLOAD_NAME=undreamai-TODO-llamacpp-linux-${{ matrix.build }}.zip" >> $GITHUB_ENV
            echo "UPLOAD_PATH=$UPLOAD_NAME" >> $GITHUB_ENV

        - id: pack_artifacts_linux
          name: Pack artifacts
          run: |
            rm build/libs/undreamai_test
            zip -j ${{ env.UPLOAD_NAME }} build/licenses/* build/libs/*

        - id: upload
          name: Upload Artifacts
          uses: actions/upload-artifact@v4
          with:
            name: ${{ env.UPLOAD_NAME }}
            path: ${{ env.UPLOAD_PATH }}


  linux-hip:
    runs-on: ubuntu-22.04
    container: rocm/dev-ubuntu-22.04:6.0.2

    env:
        CMAKE_COMMON: '-DGGML_NATIVE=OFF -DCMAKE_BUILD_RPATH_USE_ORIGIN=ON'

    strategy:
      matrix:
        include:
          - build: 'hip'

    steps:
        - id: checkout
          name: Clone
          uses: actions/checkout@v4

        - id: setup_libs_linux
          name: Dependencies
          run: |
            sudo apt-get update
            sudo apt-get install build-essential cmake zip

        - id: setup_hip_linux
          name: Dependencies
          run: |
            sudo apt-get install -y git rocblas-dev hipblas-dev

        - id: setup_llama_cpp_linux
          name: Clone llama.cpp
          run: |
            git clone https://github.com/ggerganov/llama.cpp llama.cpp
            cd llama.cpp
            git checkout ${{ env.LLAMACPP_VERSION }}
        
            sed -i 's:utils.hpp:utils_callback.hpp:g' examples/server/server.cpp
            sed -i 's:main(int argc:main_server(int argc:g' examples/server/server.cpp
            sed -i 's:exit(1):std\:\:terminate():g' ggml/src/ggml-vulkan.cpp
        
            for f in examples/server/public/*;do
              cmake -DINPUT=$f -DOUTPUT=`echo $f|sed -e 's:public/::g'`.hpp -P scripts/xxd.cmake
            done
        
            cd ..
            mkdir -p build/licenses build/libs
            cp llama.cpp/LICENSE build/licenses/llama.cpp.LICENSE.txt

        - id: set_build_params_hip_linux
          name: Set build parameters
          run: |
            sed -i "s:FATAL_ERROR:WARNING:g" llama.cpp/ggml/src/CMakeLists.txt
            echo "BUILD_PARAMS=${{ env.CMAKE_COMMON }} ${{ env.CMAKE_COMMON_JOBS }} -DCMAKE_HIP_COMPILER="$(hipconfig -l)/clang" -DGGML_HIPBLAS=ON -DCMAKE_RUNTIME_OUTPUT_DIRECTORY=`pwd`/build/libs -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=`pwd`/build/libs" >> $GITHUB_ENV

        - id: cmake_build_linux
          name: Build
          run: |
            sed -i "s:LIBRARY undreamai:LIBRARY undreamai_linux-${{ matrix.build }}:g" CMakeLists.txt
            export LD_LIBRARY_PATH=""
            cd build
            cmake .. ${{ env.BUILD_PARAMS }}
            cmake --build . --config Release -j $(nproc)

        - id: set_upload_name_linux
          name: Set upload name
          run: |
            echo "UPLOAD_NAME=undreamai-TODO-llamacpp-linux-${{ matrix.build }}.zip" >> $GITHUB_ENV
            echo "UPLOAD_PATH=$UPLOAD_NAME" >> $GITHUB_ENV

        - id: pack_artifacts_linux
          name: Pack artifacts
          run: |
            rm build/libs/undreamai_test
            zip -j ${{ env.UPLOAD_NAME }} build/licenses/* build/libs/*

        - id: upload
          name: Upload Artifacts
          uses: actions/upload-artifact@v4
          with:
            name: ${{ env.UPLOAD_NAME }}
            path: ${{ env.UPLOAD_PATH }}
